#### kafka

##### 问题
- 一个consumer如果消费了多个分区，那么怎么记录这个consumer对应的多个分区的消费位移。在zookeeper中



##### 知识点
- kafka中,replication策略是基于partition,而不是topic;kafka将每个partition数据复制到多个server上,任何一个partition有一个leader和多个follower(可以没有);
Follower就像一个"consumer
-当所有的follower都将一条消息保存成功,此消息才被认为是"committed"（有待考证，经过后面的查看，其实并不是生产者生产消息的时候，等待所有的follower同步成功，而是follower定时去leader拉取）,那么此时consumer才能消费它,这种同步策略,就要求follower和leader之间必须具有良好的网络环境.（
分布式都有这种问题，写入的时候，到底是所有的都写入才算成功，还是多数派。）
- 就是新leader server上所已经承载的partition leader的个数,如果一个server上有过多的partition leader,意味着此server将承受着更多的IO压力.
  在选举新leader,需要考虑到"负载均衡",partition leader较少的broker将会更有可能成为新的leader.
  在整几个集群中,只要有一个replicas存活,那么此partition都可以继续接受读写操作.

- 一个消息被认为是提交，必须满足所有的副本要么从同步列表中移除，要么追赶上leader，最新的消息才会认为提交。（考证）
- 一个partition对应磁盘上的一个目录 在这个partition目录下，有两类文件，一类是以log为后缀的文件，
一类是以index为后缀的文件，每一个log文件和一个index文件相对应，这一对文件就是一个segment file，也就是一个段。
- Consumer只从Leader拉取数据

终于懂了，早该想到的，kafka肯定会提供一个配置项，供生产者自己选择：
当Producer向Leader发送数据时,可以通过acks参数设置数据可靠性的级别
1.0: 不论写入是否成功,server不需要给Producer发送Response,如果发生异常,server会终止连接,触发Producer更新meta数据;
2.1: Leader写入成功后即发送Response,此种情况如果Leader fail,会丢失数据
3.-1: 等待所有ISR接收到消息后再给Producer发送Response,这是最强保证
仅设置acks=-1也不能保证数据不丢失,当Isr列表中只有Leader时,同样有可能造成数据丢失。要保证数据不丢除了设置acks=-1, 还要保 证ISR的大小大于等于2,具体参数设置:

1.request.required.acks:设置为-1 等待所有ISR列表中的Replica接收到消息后采算写成功;

2.min.insync.replicas: 设置为大于等于2,保证ISR中至少有两个Replica
Producer要在吞吐率和数据可靠性之间做一个权衡

**感觉最重要的还是这些思想**：
一致性定义:若某条消息对Consumer可见,那么即使Leader宕机了,在新Leader上数据依然可以被读到

1.HighWaterMark简称HW: Partition的高水位，取一个partition对应的ISR中最小的LEO作为HW，消费者最多只能消费到HW所在的位置，另外每个replica都有highWatermark，leader和follower各自负责更新自己的highWatermark状态，highWatermark <= leader. LogEndOffset
2.对于Leader新写入的msg，Consumer不能立刻消费，Leader会等待该消息被所有ISR中的replica同步后,更新HW,此时该消息才能被Consumer消费，即Consumer最多只能消费到HW位置
这样就保证了如果Leader Broker失效,该消息仍然可以从新选举的Leader中获取。对于来自内部Broker的读取请求,没有HW的限制。同时,Follower也会维护一份自己的HW,Folloer.HW = min(Leader.HW, Follower.offset)