#### CAP理论
> 基于网络的共享数据系统，都适用cap理论。cap理论中的C和A与传统数据库的ACID理论中A和C含义是不一样的。发明cap理论的brewer教授发表了好几篇论文来阐述具体的含义，其中中文翻译[《CAP理论十二年回顾："规则"变了》](http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed).

##### 含义
对于分布式数据存储，最多只能同时满足一致性（C，Consistency）、可用性（A， Availability）、分区容错性（P，Partition Tolerance）中的两者。
- 一致性，是指对于每一次读操作，要么都能够读到最新的数据，要么错误。
- 可用性，是指对于每一次请求，都能够得到一个及时的、非错的响应，但是不保证请求的结果是基于最新写入的数据。
- 分区容错性，是指尽管由于节点之间的网络延迟，各个节点的数据可能不一致，整个系统还能继续提供服务（提供一致性或者可用性）。

很多博客说CAP理论中的三个特性只能“三选二”，这是存在误导性的，它会过分简单化各性质之间的相互关系。有必要辨析其中的细节。实际上只有“在分区存在的前提下，要保证完美的数据一致性和可用性”这种很少见的情况是CAP理论不允许出现的。

##### 三选二的误解
“三选二”的观点在几个方面起了误导作用。首先，由于分区很少发生，那么在系统不存在分区的情况下没什么理由牺牲C或A。其次，C与A之间的取舍可以在同一系统内以非常细小的粒度反复发生，而每一次的决策可能因为具体的操作，乃至因为牵涉到特定的数据或用户而有所不同。最后，这三种性质都可以在程度上衡量，**并不是非黑即白的有或无。可用性显然是在0%到100%之间连续变化的，一致性分很多级别**，连分区也可以细分为不同含义，如系统内的不同部分对于是否存在分区可以有不一样的认知。通常认为同一个数据节点内是不存在分区的。

分区是一个相对的概念，当超过了预定的通信时限，即系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。

##### ACID、BASE、CAP
ACID注重一致性，是数据库的传统设计思路。1990年代晚期提出BASE，目的是针对高可用性的设计思路，它是“Basically Available, Soft state, Eventually consistent（基本可用、软状态、最终一致性）”的首字母缩写。其中的软状态和最终一致性这两种技巧擅于对付存在分区的场合，并因此提高了可用性。

ACID：
- A（Atomic）：原子性，构成事务的所有操作，要么都执行完成，要么全部不执行，不可能出现部分成功部分失败的情况
- C（Consistency）：一致性，在事务执行前后，数据库的一致性约束没有被破坏。实际上就是指数据库中的数据要满足已经存在的各种约束，唯一约束，非空约束等。与之相比，CAP的C仅指单一副本这个意义上的一致性，因此只是ACID一致性约束的一个严格的子集。
- I（Isolation）：隔离性，数据库中的事务一般都是并发的，隔离性是指并发的两个事务的执行互不干扰，一个事务不能看到其他事务运行过程的中间状态。数据库又分为几个隔离级别：READ_UNCOMMITTED、READ_COMMITTED
、REPEATABLE_READ、SERIALIZABLE。隔离是CAP理论关注的核心。
- D（Durability）：持久性，事务完成之后，该事务对数据的更改会被持久化到数据库，且不会被回滚。

xybaby博客中的一副描述acid和base理论的图：
![image](http://images2015.cnblogs.com/blog/1089769/201705/1089769-20170518091439963-1800029774.png)
BASE通过最终一致性来尽量保证服务的可用性，重在系统的可用性上。
CAP理论就是指导在分区发生时，如何平衡C和A的关系。

#### 分布式事务
> 当数据的规模越来越大，超出了单个关系型数据库的处理能力，这个时候就出现了关系型数据的垂直分表或者水平分表，也出现了天然支持水平扩展（sharding）的NoSql。另外，大型网站的服务化（SOA）以及这两年非常火的微服务，往往将服务进行拆分，单独部署，自然也使用独立的数据库，甚至是异构的数据库。这个时候，关系型数据库保证事务的手段，比如加锁、日志就行不通了。分布式事务是指会涉及到操作多个数据库的事务。其实就是将对同一库事务的概念扩大到了对多个库的事务。分布式事务的最大挑战在于CAP。简而言之，由于网络分割（P： Network Partition）的存在，用户不得不在一致性（C Consistency）与可用性（A： Avaliable）之前做权衡。

##### 2PC（两阶段提交）
为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提交也被称为是一种协议(Protocol))。因为数据库只知道本地事务是否成功而决定提交还是回滚。无法知道其他数据的事务执行状况。所以分布式事务中需要引入协调者，来统一决定事务的提交或回滚。

二阶段提交是指：准备阶段和提交阶段。

准备阶段：事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，**要么在本地执行事务，写本地的redo和undo日志，但不提交**。也就是说，在这里事务已经执行完成了。

![流程](http://www.hollischuang.com/wp-content/uploads/2015/12/success.png)
大概分为以下三步：
1. 协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。
2. 参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）
3.  各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。

提交阶段：
如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)。

虽然二阶段提交能解决事务的原子性，但是单点故障和网络超时的问题并没有考虑。仍然会存在数据不一致的情况。具体参考[两阶段和三阶段提交协议](http://blog.jobbole.com/95632/)

##### 三阶段提交
与两阶段提交不同的是，三阶段提交有两个改动点。

1、引入超时机制。同时在协调者和参与者中都引入超时机制。
2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。

也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。
具体流程参考上面的文章。
![三阶段提交](http://www.hollischuang.com/wp-content/uploads/2015/12/3.png)

##### 基于消息的分布式事务
上面的两阶段提交和三阶段提交都是通过网络直接通信的，是否要提交，回滚、可否提交等消息都是网络通信。每个阶段的通信还是通过消息队列来完成。比如主事务通过消息通知从事务到达预提交阶段，执行提交操作等。但是如果从事务执行失败，主事务是没办法回滚的，因此只应用于大概率成功的事务。

##### paxos
如果要保证分布式系统的数据一致性，只有一种算法，那就是paxos。


---
##### 本文参考文章
1. http://blog.jobbole.com/95632/
2. http://www.cnblogs.com/xybaby/p/7465816.html?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io
3. http://www.cnblogs.com/xybaby/p/6871764.html
4. http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed