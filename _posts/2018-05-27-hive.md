#### hive

##### 区别
hive跟mysql的语法非常相似。
hive select字句中不支持hiving字句。
没有事务、索引。
支持复杂数据类型：数字、映射、结构
不支持日期相关数据类型，提供了unix时间戳转字符串的函数。
hive提供了隐式的类型转换，也可以使用CAST('1' as INT)，来强制类型转换。
hive提供了大量的函数：日期，字符串，聚集，json相关的

**读模式、写模式**
传统数据库中，表中的数据是在加载时确定的，如果不符合规范，就不会加载数据，这个成为写时模式。
hive对数据的验证是在查询时进行的，成为读时模式。数据的加载仅仅是文件的复制或者移动，非常的快。
但是这种方式只能在查询时发现问题。hive做权衡，使用读模式。




##### hive表
hive中的数据包括元数据和数据，元数据存储在名为metastore的数据库中。
数据就是在hive指定目录下的文件，或者通过url指向存储数据的地方。一般情况下，数据存储在hdfs上，或者
其他hadoop文件系统上。

**托管表、外部表**
表的两种类型，hive会把托管表的数据放到自己的目录下进行管理，外部表只是记录一个路径，不会把数据移到
自己的数据仓库。

hive通过create table records（year string，）
drop命令删除表的元数据，如果是托管表也会删除数据。

**分区、桶**
分区的概念跟mysql的一样，比如按照日期分区，相同日期的会放到同一个目录下。一个分区会创建一个子目录。
创建表的时候，通过partitioned by命令来实现。

桶的概念就是：取一个列，然后对桶的个数取余，决定这个数据放到哪个桶中。可以对表或分区中的数据进行。
通过clustered by 实现。
create table .... clustered by (id) into 4 buckets.

可通过load data为表导入数据。
insert override table 会把原来表中的数据直接覆盖掉。
create table ... as select
alter table可以修改表的元数据，增加列等操作。

##### 查询数据
order by要求全局有序，根据hadoop知识，可知只能使用一个reducer来实现。
如果不需要全局有序可通过sort by排序，对每个reducer排序。
distribute by可控制按照哪个字段进入哪个reducer。

可以在hive使用外部脚本，python。

**连接**
select sales.*,things.&* from sales join things on (sales.id = things.id)
hive只支持在on条件里写连接条件，不支持在where里面写。并且只支持等值连接。可以多次连接，多个表。
还可以使用`explain`关键词来查看执行计划，简直跟mysql一模一样。
支持外连接 left outer join，还支持全外连接full outer join。
hive不支持in后面加查询字句，可用left semi join来替代。

hive对字查询的支持有限，只支持在from后面加子查询。

**视图**
视图的概念跟mysql一样，不过hive的视图是只读的，而且不会把视图数据存起来，而是执行sql的时候，直接
替换的。

用户自定义函数udf。



##### hive服务
- hive server，以thrift服务器的方式运作，允许不同的客户端进行访问。thrift，jdbc，odbc
- hive web interface。hive web接口。可通过http网址，访问hive。执行sql。
- metastore。元数据存储的地方。有好几种模式，local，远程模式

