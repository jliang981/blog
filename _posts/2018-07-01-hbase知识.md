#### Hbase

##### 简介
Hbase类似于一个键值的存储系统，表中的行根据键的字节序进行排序。所有对数据的访问，都要通过表的主键。
表模式定义只能列族，也就是键值对.一个表有多个列族以及每一个列族可以有任意数量的列。后续列的值连续地
存储在磁盘上。表中的每个单元格值都具有时间戳

表由行和列组成，行列交叉的位置就是单元格。单元格是有版本和时间戳的，也包含这个版本对应的值。
行中的列分为列族，相同的列族具有相同的前缀。只要列族事先存在，再更新数据时，可以动态的向列族增加新列。
hbase自动把表水平划分为分区，每个分区由表中行的子集组成。一开始表只有一个分区，当表不断扩大时，如果超过了
预先设置的容量，就会自动拆分为两个大小基本相等的分区。分区是hbase管理数据的基本单位。

hbase对行的更新是原子的。
hbase也分为管理节点（master）和数据节点（regionServer）。master负责regionServer的注册和故障恢复等。
regionServer负责分区的划分。并且集群的信息通过zookeeper来管理。

HRegion虽然是分布式存储的最小单元，但并不是存储的最小单元。　　
事实上，HRegion由一个或者多个Store组成，每个store保存一个columns family。
每个Strore又由一个memStore和0至多个StoreFile组成。如图：
![link](http://static.oschina.net/uploads/img/201411/28115110_jpY8.jpg)

Hbase将列簇的存储数据结构抽象为Store，一个Store代表一个列簇.
所以在这里也可以看出为什么在我们查询的时候要尽量减少不需要的列，而经常一起查询的列要组织到一个列簇里：因为要需要查询的列簇越多，意味着要扫描越多的Store文件，这就需要越多的时间。

##### hbase架构
hbase与传统的rdbms不同。传统的rdbms一般使用b+树做索引。b+树可以根据主键快速查找记录，并且能够方便的做范围
操作。
b+树有个问题就是，插入数据的时候，如果页表里面的数据满了，则会把一个页表分裂为两个页表。但是这两个页面并不一定
是连在一起的。如果两个页表隔的比较远，范围操作时就可能比较慢。这也是基于b+树的产品提供了optimize命令的原因。
b+树这种组织方式只是简单的按顺序把表重写。

`LSM结构`：磁盘的老问题，随机读写慢，顺序读写快（在于磁盘的寻道比较耗时）。b+树使用了磁盘的随机读能力，所以读比较快。
lsm使用了顺序写，牺牲了部分读性能。
lsm之前的数据存储读取算法：
1. 二分查找: 将文件数据有序保存，使用二分查找来完成特定key的查找。
2. 哈希：用哈希将数据分割为不同的bucket
3. B+树：使用B+树 或者 ISAM 等方法，可以减少外部文件的读取
4. 外部文件： 将数据保存为日志，并创建一个hash或者查找树映射相应的文件。
这些算法都能有效的提高读性能，但是写性能很差。

LSM树的设计思想非常朴素：将对数据的修改增量保持在内存文件中，达到指定的大小限制后将这些修改操作批量写入磁盘。
不过读取的时候稍微麻烦，需要合并磁盘中历史数据和内存中最近修改操作，所以写入性能大大提升，读取时可能需要先看是
否命中内存，否则需要访问较多的磁盘文件。


于是引入了以下的几个东西来改进它
1.      Bloom filter : 就是个带随即概率的bitmap,可以快速的告诉你，某一个小的有序结构里有没有指定的那个数据的。于是我就可以不用二分查找，而只需简单的计算几次就能知道数据是否在某个小集合里啦。效率得到了提升，但付出的是空间代价。
2.      小树合并为大树： 也就是大家经常看到的compact的过程，因为小树他性能有问题，所以要有个进程不断地将小树合并到大树上，这样大部分的老数据查询也可以直接使用log2N的方式找到，不需要再进行(N/m)*log2n的查询了。

这就是LSMTree的核心思路和优化方式。
不过，LSMTree也有个隐含的条件，就是他实现数据库的insert语义时性能不会很高，原因是，insert的含义是： 事务中，先查找该插入的数据，如果存在，则抛出异常，如果不存在则写入。这个“查找”的过程，会拖慢整个写入。


####
1. region超过指定大小之后就会拆分，持续几秒甚至更短的时间，拆分完成之后，形成两个新的region，每个region是原来
的一半。
region通过创建split目录来完成拆分过程，拆分完成后，关闭父region，父region不再接受请求。（这两个region都是新生成的，并不是说生成一个新的，
然后把数据移动给他一半）
2. 随着memstor不断的刷写到磁盘上，磁盘上文件的数量越来越多。需要一个后台线程不断地把小文件合并成大文件。当大文件的大小达到
配置的最大值，进行region分区。
3. 合并有两种，minor和major。**minor合并负责合并最新刷新到磁盘的文件**。最大处理的文件数量是10，最小文件数量是2.还可以设置文件合并大小阈值，
大于阈值的文件，不会参与合并过程。major合并允许将所有的压缩文件，压缩成一个单独文件。major可以配置一个合并周期，在固定的周期自动执行。
4. HFile格式：data，fileinfo，块大小。keyvaule格式：key包含的信息很多，列族，列名，key长度，时间戳，键类型等。有可能比值还要长很多。
所以如果值比较短的情况下，列族名和列名也要设置的小一点。